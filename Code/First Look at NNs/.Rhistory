#Load
library(keras)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(keras,install = TRUE, update = FALSE)
mnist <- dataset_mnist()
pacman::p_load(keras,install = TRUE, update = FALSE)
mnist <- dataset_mnist()
install_keras()
mnist <- dataset_mnist()
install_keras()
install_keras(tensorflow = "cpu")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(keras,install = TRUE, update = FALSE)
install_keras()
mnist <- dataset_mnist() #This will download large dataset
train_images <- array_reshape(mnist$train$x, c(60000, 28 * 28)) / 255
test_images <- array_reshape(mnist$test$x, c(10000, 28 * 28)) / 255
train_labels <- to_categorical(mnist$train$y)
test_labels <- to_categorical(mnist$test$y)
network <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
network %>% fit(train_images, train_labels, epochs = 20, batch_size = 128)
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
#Load package manager
if (!require("pacman")) install.packages("pacman")
pacman::p_load(keras,install = TRUE, update = FALSE)
#Load data
mnist <- dataset_mnist() #This will download large dataset
mnist
head(mnist)
head(mnist$train$x)
train_images <- array_reshape(mnist$train$x, c(60000, 28 * 28)) / 255
View(train_images)
size(train_images)
dim(train_images)
plot(train_images)
plot(train_images[1,:])
plot(train_images[1,])
heatmap(train_images[1,])
?heatmap
pacman::p_load(keras,install = TRUE, update = FALSE)
#Install Keras. Only need to run this once on your computer.
install_keras()
#Load package manager
if (!require("pacman")) install.packages("pacman")
pacman::p_load(keras,install = TRUE, update = FALSE)
#Load data
mnist <- dataset_mnist() #This will download large dataset, cca 200Mb
n <- 60000
train_images <- array_reshape(mnist$train$x, c(n, 28 * 28)) / 255
test_images <- array_reshape(mnist$test$x, c(n, 28 * 28)) / 255
n_test <- 10000
test_images <- array_reshape(mnist$test$x, c(n, 28 * 28)) / 255
test_images <- array_reshape(mnist$test$x, c(n_test, 28 * 28)) / 255
train_labels <- to_categorical(mnist$train$y)
test_labels <- to_categorical(mnist$test$y)
#Make some plots
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
network <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
#compile
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
#train
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
#test
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
network <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
#compile
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
#train
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
#test
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
#architecture
network <- keras_model_sequential() %>%
layer_dense(units = 32, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
#architecture
network <- keras_model_sequential() %>%
layer_dense(units = 32, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
#compile
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
#train
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
#test
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
#Change number of layers
network <- keras_model_sequential() %>%
layer_dense(units = 32, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 32, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
#Load package manager
if (!require("pacman")) install.packages("pacman")
pacman::p_load(keras,install = TRUE, update = FALSE)
#Load data
mnist <- dataset_mnist() #This will download large dataset, cca 200Mb
n <- 60000
train_images <- array_reshape(mnist$train$x, c(n, 28 * 28)) / 255
n_test <- 10000
test_images <- array_reshape(mnist$test$x, c(n_test, 28 * 28)) / 255
train_labels <- to_categorical(mnist$train$y)
test_labels <- to_categorical(mnist$test$y)
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
i <- sample(1:n, 1)
d <- array_reshape(train_images[i,],c(28,28))
plot(as.raster(d,max=1))
train_labels[i,]
test <- function(net){
#compile
net %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
#train
net %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
#test
metrics <- net %>% evaluate(test_images, test_labels, verbose = 0)
metrics
}
#Test basic net
test(net)
net <- keras_model_sequential() %>%
layer_dense(units = 32, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
test(net)
#Generate some predictions
net %>% predict_classes(test_images[1:10,])
net %>% fit(train_images, train_labels, epochs = 10, batch_size = 128)
test(net)
net <- keras_model_sequential() %>%
layer_dense(units = 32, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
#This function compiles, fits, and tests the net using default parameters
test <- function(net){
#compile
net %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
#train
net %>% fit(train_images, train_labels, epochs = 10, batch_size = 128)
#test
metrics <- net %>% evaluate(test_images, test_labels, verbose = 0)
metrics
}
#Test basic net
test(net)
net <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
test(net)
net <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 256, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
test(net)
net <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "sigmoid", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
test(net)
