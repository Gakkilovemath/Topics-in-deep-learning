\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Deep feedforward neural networks}{6}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The model}{6}{subsection.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A shallow net and a deep net\relax }}{7}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{dn}{{1}{7}{A shallow net and a deep net\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of feature learning.\relax }}{8}{figure.caption.3}}
\newlabel{fl}{{2}{8}{Example of feature learning.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Training}{9}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Backpropagation}{9}{subsubsection.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Regularization}{10}{subsubsection.1.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Other optimization steps}{11}{subsubsection.1.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Notes on using DL}{12}{subsection.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Optimization methods.\relax }}{13}{figure.caption.4}}
\newlabel{opt}{{3}{13}{Optimization methods.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Autoencoder.\relax }}{13}{figure.caption.5}}
\newlabel{ae}{{4}{13}{Autoencoder.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces AI and compute. \url  {https://blog.openai.com/ai-and-compute/}.\relax }}{14}{figure.caption.6}}
\newlabel{aic}{{5}{14}{AI and compute. \url {https://blog.openai.com/ai-and-compute/}.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tesla autopilot crash.\relax }}{15}{figure.caption.7}}
\newlabel{tes}{{6}{15}{Tesla autopilot crash.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Adversarial example.\relax }}{16}{figure.caption.8}}
\newlabel{adv}{{7}{16}{Adversarial example.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Computer vision features example.\relax }}{16}{figure.caption.9}}
\newlabel{cv}{{8}{16}{Computer vision features example.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Miscellanea}{17}{subsection.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Style transfer (Gatys et al 2015).\relax }}{18}{figure.caption.10}}
\newlabel{st}{{9}{18}{Style transfer (Gatys et al 2015).\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Statistics, ML, and AI. A humorous perspective.\relax }}{20}{figure.caption.11}}
\newlabel{mlai}{{10}{20}{Statistics, ML, and AI. A humorous perspective.\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces DL and statistics\relax }}{20}{table.caption.12}}
\newlabel{my-label}{{1}{20}{DL and statistics\relax }{table.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Creative architectures.\relax }}{22}{figure.caption.13}}
\newlabel{arch}{{11}{22}{Creative architectures.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Ideas}{23}{subsection.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Convolutional neural networks (CNNs)}{23}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The problem and model}{23}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces LeNet-5. (LeCun, 1998)\relax }}{24}{figure.caption.14}}
\newlabel{lenet5}{{12}{24}{LeNet-5. (LeCun, 1998)\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces AlexNet. Krizhevsky et al (2012, NIPS), Won ILSVRC 2012.\relax }}{25}{figure.caption.15}}
\newlabel{AlexNet}{{13}{25}{AlexNet. Krizhevsky et al (2012, NIPS), Won ILSVRC 2012.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces VGG. (Simonyan, Zisserman, 2015).\relax }}{25}{figure.caption.16}}
\newlabel{VGG}{{14}{25}{VGG. (Simonyan, Zisserman, 2015).\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Visualization}{25}{subsubsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Images that maximize activation. The neurons selected for these images are the output neurons that a DNN uses to classify images as bananas etc.\relax }}{26}{figure.caption.17}}
\newlabel{vis}{{15}{26}{Images that maximize activation. The neurons selected for these images are the output neurons that a DNN uses to classify images as bananas etc.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Other methodology}{26}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Deepvis.\relax }}{27}{figure.caption.18}}
\newlabel{Deepvis}{{16}{27}{Deepvis.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces R-CNN.\relax }}{28}{figure.caption.19}}
\newlabel{rcnn}{{17}{28}{R-CNN.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training}{28}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Graph CNN}{28}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Graph CNN.\relax }}{31}{figure.caption.20}}
\newlabel{gcnn}{{18}{31}{Graph CNN.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Graph Coarsening and Pooling.\relax }}{32}{figure.caption.21}}
\newlabel{gcp}{{19}{32}{Graph Coarsening and Pooling.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Other aspects}{34}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Shapes beyond images, invariance}{35}{subsection.2.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Spatial Transformer Networks.\relax }}{40}{figure.caption.22}}
\newlabel{STN}{{20}{40}{Spatial Transformer Networks.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Spatial Transformer Networks}{40}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Image denoising/compression}{40}{subsection.2.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Unsupervised Adversarial Image Reconstruction.\relax }}{41}{figure.caption.23}}
\newlabel{UAIR}{{21}{41}{Unsupervised Adversarial Image Reconstruction.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Unsupervised Adversarial Image Reconstruction results example.\relax }}{42}{figure.caption.24}}
\newlabel{UAIRr}{{22}{42}{Unsupervised Adversarial Image Reconstruction results example.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Deep decoder.\relax }}{42}{figure.caption.25}}
\newlabel{DD}{{23}{42}{Deep decoder.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Recurrent neural networks (RNNs)}{43}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Setup}{43}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces RNNs.\relax }}{44}{figure.caption.26}}
\newlabel{rnn}{{24}{44}{RNNs.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces LSTM. Courtesy of Andrew Ng's course.\relax }}{45}{figure.caption.27}}
\newlabel{lstm}{{25}{45}{LSTM. Courtesy of Andrew Ng's course.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Attention Model.\relax }}{46}{figure.caption.28}}
\newlabel{attn}{{26}{46}{Attention Model.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sequence Learning}{46}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Motivation}{46}{subsubsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Captioning, Google Brain, 2016. Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. \url  {https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html}\relax }}{47}{figure.caption.29}}
\newlabel{c}{{27}{47}{Captioning, Google Brain, 2016. Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. \url {https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html}\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces MLP.\relax }}{47}{figure.caption.30}}
\newlabel{MLP}{{28}{47}{MLP.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces RNN types.\relax }}{48}{figure.caption.31}}
\newlabel{rnn-types}{{29}{48}{RNN types.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Simple RNN.\relax }}{48}{figure.caption.32}}
\newlabel{Simple RNN}{{30}{48}{Simple RNN.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sequence Models}{48}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}RNNs}{48}{subsubsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Teacher forcing.\relax }}{49}{figure.caption.33}}
\newlabel{Teacher forcing}{{31}{49}{Teacher forcing.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Training Challenges}{50}{subsubsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Gradient Clipping.\relax }}{51}{figure.caption.34}}
\newlabel{Gradient Clipping}{{32}{51}{Gradient Clipping.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces ReLU.\relax }}{52}{figure.caption.35}}
\newlabel{ReLU}{{33}{52}{ReLU.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}LSTM and GRU}{52}{subsubsection.3.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces LSTM.\relax }}{53}{figure.caption.36}}
\newlabel{LSTM}{{34}{53}{LSTM.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Machine Translation}{53}{subsection.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Neural Machine Translation in 2016.\relax }}{54}{figure.caption.37}}
\newlabel{Neural Machine Translation in 2016}{{35}{54}{Neural Machine Translation in 2016.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Translation quality vs. sentence length. RNN left, SMT right.\relax }}{55}{figure.caption.38}}
\newlabel{Encoder-Decoder Model}{{36}{55}{Translation quality vs. sentence length. RNN left, SMT right.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Sample output of two RNN models compared to the SMT system, Moses.\relax }}{56}{figure.caption.39}}
\newlabel{Sample-rnn}{{37}{56}{Sample output of two RNN models compared to the SMT system, Moses.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Attention}{56}{subsubsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Attention\relax }}{57}{figure.caption.40}}
\newlabel{Attention}{{38}{57}{Attention\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Encoder-Decoder Model with Attention.\relax }}{57}{figure.caption.41}}
\newlabel{Encoder-Decoder Model with Attention}{{39}{57}{Encoder-Decoder Model with Attention.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Transformer Model}{57}{subsubsection.3.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces A sample alignment found by RNNsearch-50.\relax }}{58}{figure.caption.42}}
\newlabel{A sample alignment found by RNNsearch-50}{{40}{58}{A sample alignment found by RNNsearch-50.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces $n$ is sequence length, $d$ is representation dimension, $k$ is kernel size of convolutions, $r$ is the size of the neighborhood in restricted self-attention.\relax }}{58}{figure.caption.43}}
\newlabel{NMT Model Comparison}{{41}{58}{$n$ is sequence length, $d$ is representation dimension, $k$ is kernel size of convolutions, $r$ is the size of the neighborhood in restricted self-attention.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Transformer Model.\relax }}{59}{figure.caption.44}}
\newlabel{Transformer Model}{{42}{59}{Transformer Model.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Self-Attention.\relax }}{60}{figure.caption.45}}
\newlabel{Self-Attention}{{43}{60}{Self-Attention.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Self-Attention 1.\relax }}{60}{figure.caption.46}}
\newlabel{Self-Attention 1}{{44}{60}{Self-Attention 1.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Self-Attention 2\relax }}{61}{figure.caption.47}}
\newlabel{Self-Attention 2}{{45}{61}{Self-Attention 2\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Self-Attention 3\relax }}{62}{figure.caption.48}}
\newlabel{Self-Attention 3}{{46}{62}{Self-Attention 3\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces The Transformer outperforms other state-of-the-art models at a fraction of the training cost. FLOPS is floating point operations.\relax }}{62}{figure.caption.49}}
\newlabel{TheT}{{47}{62}{The Transformer outperforms other state-of-the-art models at a fraction of the training cost. FLOPS is floating point operations.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Deep Visual-Semantic Alignments for Generating Image Descriptions\relax }}{63}{figure.caption.50}}
\newlabel{Caption}{{48}{63}{Deep Visual-Semantic Alignments for Generating Image Descriptions\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Image + Text}{63}{subsection.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Others}{64}{subsection.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Unsupervised learning}{64}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Setup}{64}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces TCN\relax }}{65}{figure.caption.51}}
\newlabel{TCN}{{49}{65}{TCN\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Wavenet.\relax }}{66}{figure.caption.52}}
\newlabel{wavenet}{{50}{66}{Wavenet.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}PCA, AE, VAE}{66}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces AE\relax }}{67}{figure.caption.53}}
\newlabel{ae0}{{51}{67}{AE\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces VAE\relax }}{68}{figure.caption.54}}
\newlabel{vae}{{52}{68}{VAE\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Sampling process of VAEs.\relax }}{69}{figure.caption.55}}
\newlabel{svae}{{53}{69}{Sampling process of VAEs.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Reparameterization trick for VAEs.\relax }}{70}{figure.caption.56}}
\newlabel{Reparam}{{54}{70}{Reparameterization trick for VAEs.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Framework of VAEs.\relax }}{70}{figure.caption.57}}
\newlabel{VAE_Process}{{55}{70}{Framework of VAEs.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces Generated faces\relax }}{71}{figure.caption.59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Generative adversarial networks (GAN)}{71}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces GAN\relax }}{72}{figure.caption.60}}
\newlabel{gan}{{57}{72}{GAN\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces GAN Example\relax }}{72}{figure.caption.61}}
\newlabel{gan1}{{58}{72}{GAN Example\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces GAN Example\relax }}{73}{figure.caption.62}}
\newlabel{gan2}{{59}{73}{GAN Example\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces Mode collapse. Top: "Unrolled GAN", bottom: standard GAN\relax }}{75}{figure.caption.63}}
\newlabel{mc}{{60}{75}{Mode collapse. Top: "Unrolled GAN", bottom: standard GAN\relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Wasserstein GAN}{75}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}WGAN}{77}{subsubsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces WGAN algorithm\relax }}{78}{figure.caption.64}}
\newlabel{wgan}{{61}{78}{WGAN algorithm\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces GAN algorithm\relax }}{78}{figure.caption.65}}
\newlabel{gan_alg}{{62}{78}{GAN algorithm\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces Wasserstein distance is highly correlated with the generator's convergence and sample quality.\relax }}{79}{figure.caption.66}}
\newlabel{wass_qual}{{63}{79}{Wasserstein distance is highly correlated with the generator's convergence and sample quality.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Gradient penalty}{79}{subsubsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {64}{\ignorespaces (left) gradient norms of deep WGAN critics during training on the Swiss Roll dateset either expolde or vanish when using weight clipping, but not when using a gradient penalty. (right) Weight clipping pushes weights towards the extremes of the clipping range, unlike gradient penalty.\relax }}{79}{figure.caption.67}}
\newlabel{explode}{{64}{79}{(left) gradient norms of deep WGAN critics during training on the Swiss Roll dateset either expolde or vanish when using weight clipping, but not when using a gradient penalty. (right) Weight clipping pushes weights towards the extremes of the clipping range, unlike gradient penalty.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {65}{\ignorespaces Weight clipping reduces the capacity of the critic f and limits the capability to model complex functions.\relax }}{80}{figure.caption.68}}
\newlabel{value}{{65}{80}{Weight clipping reduces the capacity of the critic f and limits the capability to model complex functions.\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {66}{\ignorespaces WGAN Gradient Penalty.\relax }}{81}{figure.caption.69}}
\newlabel{wgan_gp}{{66}{81}{WGAN Gradient Penalty.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Other GANs}{81}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {67}{\ignorespaces WGAN Gradient Penalty. Experimental results\relax }}{82}{figure.caption.70}}
\newlabel{wgan_gp_exp}{{67}{82}{WGAN Gradient Penalty. Experimental results\relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {68}{\ignorespaces cGAN\relax }}{82}{figure.caption.71}}
\newlabel{cGAN}{{68}{82}{cGAN\relax }{figure.caption.71}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Other questions in unsupervised learning}{83}{subsection.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Other questions in unsupervised learning}{84}{subsection.4.7}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Sequential decision-making: from bandits to deep reinforcement learning}{85}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Intro}{85}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {69}{\ignorespaces Bandit example\relax }}{86}{figure.caption.72}}
\newlabel{band_ex}{{69}{86}{Bandit example\relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {70}{\ignorespaces Online advertising\relax }}{86}{figure.caption.73}}
\newlabel{online_ad}{{70}{86}{Online advertising\relax }{figure.caption.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Bandits}{86}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {71}{\ignorespaces Adaptive clinical trials\relax }}{87}{figure.caption.74}}
\newlabel{ada_ct}{{71}{87}{Adaptive clinical trials\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {72}{\ignorespaces Robotics\relax }}{88}{figure.caption.75}}
\newlabel{robo}{{72}{88}{Robotics\relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {73}{\ignorespaces Reward distribution for two arms\relax }}{88}{figure.caption.76}}
\newlabel{rewards}{{73}{88}{Reward distribution for two arms\relax }{figure.caption.76}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Policies and regret analysis}{89}{subsubsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {74}{\ignorespaces Optimism Principle\relax }}{90}{figure.caption.77}}
\newlabel{opti}{{74}{90}{Optimism Principle\relax }{figure.caption.77}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Comparing policies}{92}{subsubsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {75}{\ignorespaces K=5, $\sigma =0.01$\relax }}{92}{figure.caption.78}}
\newlabel{K=5.sigma=0.01}{{75}{92}{K=5, $\sigma =0.01$\relax }{figure.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {76}{\ignorespaces K=5, $\sigma =0.1$\relax }}{93}{figure.caption.79}}
\newlabel{K=5.sigma=0.1}{{76}{93}{K=5, $\sigma =0.1$\relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {77}{\ignorespaces K=2, $\sigma =0.01$\relax }}{94}{figure.caption.80}}
\newlabel{K=2.sigma=0.01}{{77}{94}{K=2, $\sigma =0.01$\relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {78}{\ignorespaces Thompson sampling\relax }}{95}{figure.caption.81}}
\newlabel{Thompson sampling}{{78}{95}{Thompson sampling\relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Adversarial bandits}{95}{subsubsection.5.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Contextual Bandits}{97}{subsubsection.5.2.4}}
\newlabel{Stochastic Contextual Bandits: Parametric Approach III}{{\caption@xref {Stochastic Contextual Bandits: Parametric Approach III}{ on input line 4553}}{99}{Contextual Bandits}{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {79}{\ignorespaces Stochastic Contextual Bandits: Parametric Approach III\relax }}{99}{figure.caption.82}}
\newlabel{Yang and Zhu (2002)}{{\caption@xref {Yang and Zhu (2002)}{ on input line 4566}}{100}{Contextual Bandits}{figure.caption.83}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {80}{\ignorespaces SYang and Zhu (2002)\relax }}{100}{figure.caption.83}}
\newlabel{Adversarial Contexts with Stochastic Rewards 1}{{\caption@xref {Adversarial Contexts with Stochastic Rewards 1}{ on input line 4588}}{100}{Contextual Bandits}{figure.caption.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {81}{\ignorespaces Adversarial Contexts with Stochastic Rewards 2\relax }}{100}{figure.caption.84}}
\newlabel{Adversarial Contexts with Stochastic Rewards 2}{{\caption@xref {Adversarial Contexts with Stochastic Rewards 2}{ on input line 4605}}{101}{Contextual Bandits}{figure.caption.85}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {82}{\ignorespaces Adversarial Contexts with Stochastic Rewards 2\relax }}{101}{figure.caption.85}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Software and Miscellanea}{102}{subsubsection.5.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Reinforcement learning}{102}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Setup}{102}{subsubsection.5.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}L1. Introduction}{102}{subsubsection.5.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {83}{\ignorespaces Example RL\relax }}{103}{figure.caption.86}}
\newlabel{Example RL}{{83}{103}{Example RL\relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {84}{\ignorespaces Agent and Environment\relax }}{104}{figure.caption.87}}
\newlabel{Agent and Environment}{{84}{104}{Agent and Environment\relax }{figure.caption.87}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Definitions}{104}{subsubsection.5.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Relation to Contextual Bandits}{106}{subsubsection.5.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {85}{\ignorespaces Comparing bandits and RL\relax }}{107}{figure.caption.88}}
\newlabel{Comparing bandits and RL}{{85}{107}{Comparing bandits and RL\relax }{figure.caption.88}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5}Markov Decision Process}{107}{subsubsection.5.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {86}{\ignorespaces Maze and Value-based\relax }}{110}{figure.caption.89}}
\newlabel{maze}{{86}{110}{Maze and Value-based\relax }{figure.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {87}{\ignorespaces Policy and Model-based\relax }}{110}{figure.caption.90}}
\newlabel{maze2}{{87}{110}{Policy and Model-based\relax }{figure.caption.90}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6}Planning by dynamic programming}{111}{subsubsection.5.3.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7}Model-free prediction}{111}{subsubsection.5.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {88}{\ignorespaces Unified view of RL\relax }}{112}{figure.caption.91}}
\newlabel{Unified view of RL}{{88}{112}{Unified view of RL\relax }{figure.caption.91}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.8}Model-free control}{113}{subsubsection.5.3.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.9}Scaling up RL. Value function approximation}{113}{subsubsection.5.3.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.10}Policy gradient}{114}{subsubsection.5.3.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.11}Integrating learning and planning}{115}{subsubsection.5.3.11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.12}Hierarchical RL}{116}{subsubsection.5.3.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {89}{\ignorespaces Maze Task.\relax }}{117}{figure.caption.92}}
\newlabel{maze10}{{89}{117}{Maze Task.\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.13}Task-agnostic RL}{123}{subsubsection.5.3.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Other topics}{124}{subsection.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Special topics}{125}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Adversarial examples}{125}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {90}{\ignorespaces A conceptual illustration of “natural” vs. “adversarial” decision boundaries.\relax }}{128}{figure.caption.93}}
\newlabel{natl_adv}{{90}{128}{A conceptual illustration of “natural” vs. “adversarial” decision boundaries.\relax }{figure.caption.93}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {91}{\ignorespaces EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY.\relax }}{130}{figure.caption.94}}
\newlabel{inv}{{91}{130}{EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY.\relax }{figure.caption.94}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Neural ODEs}{130}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Physics informed NNs (PINNs)}{131}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Information bottleneck and invariance}{132}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Gradient-based optimization}{134}{subsection.6.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {92}{\ignorespaces Gradient descent\relax }}{135}{figure.caption.95}}
\newlabel{Gradient descent}{{92}{135}{Gradient descent\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {93}{\ignorespaces Batch gradient descent vs. SGD fluctuation (Source: Wikipedia)\relax }}{136}{figure.caption.96}}
\newlabel{Batch gradient descent vs. SGD fluctuation}{{93}{136}{Batch gradient descent vs. SGD fluctuation (Source: Wikipedia)\relax }{figure.caption.96}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {94}{\ignorespaces Tradeoffs\relax }}{137}{figure.caption.97}}
\newlabel{Tradeoffs}{{94}{137}{Tradeoffs\relax }{figure.caption.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {95}{\ignorespaces Ravine\relax }}{137}{figure.caption.98}}
\newlabel{Ravine}{{95}{137}{Ravine\relax }{figure.caption.98}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {96}{\ignorespaces Ravine in optimization\relax }}{137}{figure.caption.98}}
\@writefile{lof}{\contentsline {figure}{\numberline {97}{\ignorespaces SGD without momentum\relax }}{138}{figure.caption.99}}
\newlabel{SGD with momentum}{{97}{138}{SGD without momentum\relax }{figure.caption.99}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {98}{\ignorespaces SGD with momentum\relax }}{138}{figure.caption.99}}
\@writefile{lof}{\contentsline {figure}{\numberline {99}{\ignorespaces Optimization with momentum (Source: \href  {https://distill.pub/2017/momentum/}{distill.pub})\relax }}{138}{figure.caption.100}}
\newlabel{Momentum}{{99}{138}{Optimization with momentum (Source: \href {https://distill.pub/2017/momentum/}{distill.pub})\relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {100}{\ignorespaces Nesterov\relax }}{139}{figure.caption.101}}
\newlabel{Nesterov}{{100}{139}{Nesterov\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {101}{\ignorespaces Animations\relax }}{140}{figure.caption.102}}
\newlabel{animations}{{101}{140}{Animations\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {102}{\ignorespaces Logistic regression experiment\relax }}{142}{figure.caption.103}}
\newlabel{experiment_logistic_regression}{{102}{142}{Logistic regression experiment\relax }{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {103}{\ignorespaces Experiment: Convolutional Neural Networks\relax }}{142}{figure.caption.104}}
\newlabel{experiment_cnn}{{103}{142}{Experiment: Convolutional Neural Networks\relax }{figure.caption.104}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {104}{\ignorespaces NMT1\relax }}{144}{figure.caption.105}}
\newlabel{NMT1}{{104}{144}{NMT1\relax }{figure.caption.105}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {105}{\ignorespaces NMT2\relax }}{145}{figure.caption.106}}
\newlabel{NMT2}{{105}{145}{NMT2\relax }{figure.caption.106}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Design of new architectures - gradient computations}{145}{subsection.6.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Distributed training}{146}{subsection.6.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {106}{\ignorespaces MapReduce\relax }}{147}{figure.caption.107}}
\newlabel{mr}{{106}{147}{MapReduce\relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {107}{\ignorespaces Distributed GD\relax }}{148}{figure.caption.108}}
\newlabel{dgd}{{107}{148}{Distributed GD\relax }{figure.caption.108}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {108}{\ignorespaces FireCaffe: near-linear acceleration of deep neural network training on compute clusters, Iandola et al 2016\relax }}{148}{figure.caption.109}}
\newlabel{FireCaffe}{{108}{148}{FireCaffe: near-linear acceleration of deep neural network training on compute clusters, Iandola et al 2016\relax }{figure.caption.109}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.1}Notes from Smola's class}{149}{subsubsection.6.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}AutoML}{151}{subsection.6.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {109}{\ignorespaces Universal relationship between batch size and training speed\relax }}{152}{figure.caption.110}}
\newlabel{Bsts}{{109}{152}{Universal relationship between batch size and training speed\relax }{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {110}{\ignorespaces Neural Architecture Search\relax }}{153}{figure.caption.111}}
\newlabel{nas}{{110}{153}{Neural Architecture Search\relax }{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {111}{\ignorespaces Basic Neural Architecture Search Spaces\relax }}{153}{figure.caption.112}}
\newlabel{nas2}{{111}{153}{Basic Neural Architecture Search Spaces\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {112}{\ignorespaces Cell Search Spaces.\relax }}{154}{figure.caption.113}}
\newlabel{nas3}{{112}{154}{Cell Search Spaces.\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {113}{\ignorespaces NAS as Hyperparameter Optimization\relax }}{154}{figure.caption.114}}
\newlabel{nas4}{{113}{154}{NAS as Hyperparameter Optimization\relax }{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {114}{\ignorespaces NAS with RL.\relax }}{155}{figure.caption.115}}
\newlabel{nas6}{{114}{155}{NAS with RL.\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {115}{\ignorespaces Controller.\relax }}{156}{figure.caption.116}}
\newlabel{nas7}{{115}{156}{Controller.\relax }{figure.caption.116}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {116}{\ignorespaces Evolution.\relax }}{156}{figure.caption.117}}
\newlabel{nas8}{{116}{156}{Evolution.\relax }{figure.caption.117}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {117}{\ignorespaces Comparison: Evolution, RL.\relax }}{157}{figure.caption.118}}
\newlabel{nas9}{{117}{157}{Comparison: Evolution, RL.\relax }{figure.caption.118}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {118}{\ignorespaces One-shot NAS.\relax }}{157}{figure.caption.119}}
\newlabel{nas10}{{118}{157}{One-shot NAS.\relax }{figure.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {119}{\ignorespaces DARTS\relax }}{158}{figure.caption.120}}
\newlabel{darts}{{119}{158}{DARTS\relax }{figure.caption.120}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {120}{\ignorespaces Google's AutoML system pipeline\relax }}{161}{figure.caption.121}}
\newlabel{automl}{{120}{161}{Google's AutoML system pipeline\relax }{figure.caption.121}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9}Biological plausibility}{161}{subsection.6.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.10}Accessibility + Human-centric AI}{161}{subsection.6.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {121}{\ignorespaces Penn AI\relax }}{162}{figure.caption.122}}
\newlabel{Penn AI}{{121}{162}{Penn AI\relax }{figure.caption.122}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11}Explainability (and interpretability)}{162}{subsection.6.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {122}{\ignorespaces Saliency maps\relax }}{163}{figure.caption.123}}
\newlabel{saliency}{{122}{163}{Saliency maps\relax }{figure.caption.123}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.12}Model compression}{166}{subsection.6.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {123}{\ignorespaces Lottery ticket hypothesis\relax }}{167}{figure.caption.124}}
\newlabel{lot}{{123}{167}{Lottery ticket hypothesis\relax }{figure.caption.124}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13}Others}{168}{subsection.6.13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.1}List}{168}{subsubsection.6.13.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.2}Privacy}{169}{subsubsection.6.13.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.3}Applications}{169}{subsubsection.6.13.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {124}{\ignorespaces Model architecture using a graph-based convolutional neural network for molecular embedding.\relax }}{170}{figure.caption.125}}
\newlabel{gcnn_mol}{{124}{170}{Model architecture using a graph-based convolutional neural network for molecular embedding.\relax }{figure.caption.125}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Theory}{170}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Why do we need theory?}{170}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Computational complexity and learning}{171}{subsection.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {125}{\ignorespaces 3-Node Neural Network that is NP-Complete to train. Blum and Rivest\relax }}{172}{figure.caption.126}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Approximation theory}{174}{subsection.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Optimization}{175}{subsection.7.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Generalization}{177}{subsection.7.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Nonparametric function estimation}{179}{subsection.7.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7}Harmonic analysis}{179}{subsection.7.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8}Probabilistic ML}{179}{subsection.7.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {126}{\ignorespaces Deep Scattering Network, Boelcskei \& Wiatkowski, 2015\relax }}{180}{figure.caption.127}}
\newlabel{dsn}{{126}{180}{Deep Scattering Network, Boelcskei \& Wiatkowski, 2015\relax }{figure.caption.127}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {127}{\ignorespaces Rendering Mixture Model, Baraniuk, Patel, etc\relax }}{180}{figure.caption.128}}
\newlabel{rmm}{{127}{180}{Rendering Mixture Model, Baraniuk, Patel, etc\relax }{figure.caption.128}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9}Information geometry}{180}{subsection.7.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10}Random Matrix Theory}{181}{subsection.7.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11}Physics}{182}{subsection.7.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.12}Geometry}{184}{subsection.7.12}}
\@writefile{toc}{\contentsline {section}{\numberline {8}How to learn practical DL}{184}{section.8}}
