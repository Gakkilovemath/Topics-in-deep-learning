\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Deep feedforward neural networks}{3}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The model}{3}{subsection.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A shallow net and a deep net\relax }}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{dn}{{1}{4}{A shallow net and a deep net\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of feature learning.\relax }}{5}{figure.caption.3}}
\newlabel{fl}{{2}{5}{Example of feature learning.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Training}{6}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Backpropagation}{6}{subsubsection.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Regularization}{8}{subsubsection.1.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Other optimization steps}{8}{subsubsection.1.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Notes on using DL}{9}{subsection.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Optimization methods.\relax }}{10}{figure.caption.4}}
\newlabel{opt}{{3}{10}{Optimization methods.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Autoencoder.\relax }}{10}{figure.caption.5}}
\newlabel{ae}{{4}{10}{Autoencoder.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces AI and compute. \url  {https://blog.openai.com/ai-and-compute/}.\relax }}{11}{figure.caption.6}}
\newlabel{aic}{{5}{11}{AI and compute. \url {https://blog.openai.com/ai-and-compute/}.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tesla autopilot crash.\relax }}{12}{figure.caption.7}}
\newlabel{tes}{{6}{12}{Tesla autopilot crash.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Adversarial example.\relax }}{13}{figure.caption.8}}
\newlabel{adv}{{7}{13}{Adversarial example.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Computer vision features example.\relax }}{14}{figure.caption.9}}
\newlabel{cv}{{8}{14}{Computer vision features example.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Miscellanea}{14}{subsection.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Style transfer (Gatys et al 2015).\relax }}{15}{figure.caption.10}}
\newlabel{st}{{9}{15}{Style transfer (Gatys et al 2015).\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Statistics, ML, and AI. A humorous perspective.\relax }}{17}{figure.caption.11}}
\newlabel{mlai}{{10}{17}{Statistics, ML, and AI. A humorous perspective.\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces DL and statistics\relax }}{17}{table.caption.12}}
\newlabel{my-label}{{1}{17}{DL and statistics\relax }{table.caption.12}{}}
<<<<<<< HEAD
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Creative architectures.\relax }}{19}{figure.caption.13}}
\newlabel{arch}{{11}{19}{Creative architectures.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Ideas}{20}{subsection.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Convolutional neural networks (CNNs)}{20}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The problem and model}{20}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces LeNet-5. (LeCun, 1998)\relax }}{21}{figure.caption.14}}
\newlabel{lenet5}{{12}{21}{LeNet-5. (LeCun, 1998)\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces AlexNet. Krizhevsky et al (2012, NIPS), Won ILSVRC 2012.\relax }}{22}{figure.caption.15}}
\newlabel{AlexNet}{{13}{22}{AlexNet. Krizhevsky et al (2012, NIPS), Won ILSVRC 2012.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces VGG. (Simonyan, Zisserman, 2015).\relax }}{22}{figure.caption.16}}
\newlabel{VGG}{{14}{22}{VGG. (Simonyan, Zisserman, 2015).\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Visualization}{22}{subsubsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Images that maximize activation. The neurons selected for these images are the output neurons that a DNN uses to classify images as bananas etc.\relax }}{23}{figure.caption.17}}
\newlabel{vis}{{15}{23}{Images that maximize activation. The neurons selected for these images are the output neurons that a DNN uses to classify images as bananas etc.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Other methodology}{23}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Deepvis.\relax }}{24}{figure.caption.18}}
\newlabel{Deepvis}{{16}{24}{Deepvis.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces R-CNN.\relax }}{25}{figure.caption.19}}
\newlabel{rcnn}{{17}{25}{R-CNN.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training}{25}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Graph CNN}{25}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Graph CNN.\relax }}{28}{figure.caption.20}}
\newlabel{gcnn}{{18}{28}{Graph CNN.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Graph Coarsening and Pooling.\relax }}{29}{figure.caption.21}}
\newlabel{gcp}{{19}{29}{Graph Coarsening and Pooling.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Other aspects}{31}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Shapes beyond images, invariance}{32}{subsection.2.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Spatial Transformer Networks.\relax }}{37}{figure.caption.22}}
\newlabel{STN}{{20}{37}{Spatial Transformer Networks.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Spatial Transformer Networks}{37}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Image denoising/compression}{37}{subsection.2.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Unsupervised Adversarial Image Reconstruction.\relax }}{38}{figure.caption.23}}
\newlabel{UAIR}{{21}{38}{Unsupervised Adversarial Image Reconstruction.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Unsupervised Adversarial Image Reconstruction results example.\relax }}{39}{figure.caption.24}}
\newlabel{UAIRr}{{22}{39}{Unsupervised Adversarial Image Reconstruction results example.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Deep decoder.\relax }}{39}{figure.caption.25}}
\newlabel{DD}{{23}{39}{Deep decoder.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Recurrent neural networks (RNNs)}{40}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Setup}{40}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces RNNs.\relax }}{41}{figure.caption.26}}
\newlabel{rnn}{{24}{41}{RNNs.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces LSTM. Courtesy of Andrew Ng's course.\relax }}{42}{figure.caption.27}}
\newlabel{lstm}{{25}{42}{LSTM. Courtesy of Andrew Ng's course.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Attention Model.\relax }}{43}{figure.caption.28}}
\newlabel{attn}{{26}{43}{Attention Model.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sequence Learning}{43}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Motivation}{43}{subsubsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Captioning, Google Brain, 2016. Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. \url  {https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html}\relax }}{44}{figure.caption.29}}
\newlabel{c}{{27}{44}{Captioning, Google Brain, 2016. Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. \url {https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html}\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces MLP.\relax }}{44}{figure.caption.30}}
\newlabel{MLP}{{28}{44}{MLP.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces RNN types.\relax }}{45}{figure.caption.31}}
\newlabel{rnn-types}{{29}{45}{RNN types.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Simple RNN.\relax }}{45}{figure.caption.32}}
\newlabel{Simple RNN}{{30}{45}{Simple RNN.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sequence Models}{45}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}RNNs}{45}{subsubsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Teacher forcing.\relax }}{46}{figure.caption.33}}
\newlabel{Teacher forcing}{{31}{46}{Teacher forcing.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Training Challenges}{47}{subsubsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Gradient Clipping.\relax }}{48}{figure.caption.34}}
\newlabel{Gradient Clipping}{{32}{48}{Gradient Clipping.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces ReLU.\relax }}{49}{figure.caption.35}}
\newlabel{ReLU}{{33}{49}{ReLU.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}LSTM and GRU}{49}{subsubsection.3.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces LSTM.\relax }}{50}{figure.caption.36}}
\newlabel{LSTM}{{34}{50}{LSTM.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Machine Translation}{50}{subsection.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Neural Machine Translation in 2016.\relax }}{51}{figure.caption.37}}
\newlabel{Neural Machine Translation in 2016}{{35}{51}{Neural Machine Translation in 2016.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Translation quality vs. sentence length. RNN left, SMT right.\relax }}{52}{figure.caption.38}}
\newlabel{Encoder-Decoder Model}{{36}{52}{Translation quality vs. sentence length. RNN left, SMT right.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Sample output of two RNN models compared to the SMT system, Moses.\relax }}{53}{figure.caption.39}}
\newlabel{Sample-rnn}{{37}{53}{Sample output of two RNN models compared to the SMT system, Moses.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Attention}{53}{subsubsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Attention\relax }}{54}{figure.caption.40}}
\newlabel{Attention}{{38}{54}{Attention\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Encoder-Decoder Model with Attention.\relax }}{54}{figure.caption.41}}
\newlabel{Encoder-Decoder Model with Attention}{{39}{54}{Encoder-Decoder Model with Attention.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Transformer Model}{54}{subsubsection.3.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces A sample alignment found by RNNsearch-50.\relax }}{55}{figure.caption.42}}
\newlabel{A sample alignment found by RNNsearch-50}{{40}{55}{A sample alignment found by RNNsearch-50.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces $n$ is sequence length, $d$ is representation dimension, $k$ is kernel size of convolutions, $r$ is the size of the neighborhood in restricted self-attention.\relax }}{55}{figure.caption.43}}
\newlabel{NMT Model Comparison}{{41}{55}{$n$ is sequence length, $d$ is representation dimension, $k$ is kernel size of convolutions, $r$ is the size of the neighborhood in restricted self-attention.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Transformer Model.\relax }}{56}{figure.caption.44}}
\newlabel{Transformer Model}{{42}{56}{Transformer Model.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Self-Attention.\relax }}{57}{figure.caption.45}}
\newlabel{Self-Attention}{{43}{57}{Self-Attention.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Self-Attention 1.\relax }}{57}{figure.caption.46}}
\newlabel{Self-Attention 1}{{44}{57}{Self-Attention 1.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Self-Attention 2\relax }}{58}{figure.caption.47}}
\newlabel{Self-Attention 2}{{45}{58}{Self-Attention 2\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Self-Attention 3\relax }}{59}{figure.caption.48}}
\newlabel{Self-Attention 3}{{46}{59}{Self-Attention 3\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces The Transformer outperforms other state-of-the-art models at a fraction of the training cost. FLOPS is floating point operations.\relax }}{59}{figure.caption.49}}
\newlabel{TheT}{{47}{59}{The Transformer outperforms other state-of-the-art models at a fraction of the training cost. FLOPS is floating point operations.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Deep Visual-Semantic Alignments for Generating Image Descriptions\relax }}{60}{figure.caption.50}}
\newlabel{Caption}{{48}{60}{Deep Visual-Semantic Alignments for Generating Image Descriptions\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Image + Text}{60}{subsection.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces TCN\relax }}{61}{figure.caption.51}}
\newlabel{TCN}{{49}{61}{TCN\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Others}{61}{subsection.3.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Wavenet.\relax }}{62}{figure.caption.52}}
\newlabel{wavenet}{{50}{62}{Wavenet.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Unsupervised learning}{62}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Setup}{62}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}PCA, AE, VAE}{63}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces AE\relax }}{64}{figure.caption.53}}
\newlabel{ae0}{{51}{64}{AE\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces VAE\relax }}{64}{figure.caption.54}}
\newlabel{vae}{{52}{64}{VAE\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Sampling process of VAEs.\relax }}{65}{figure.caption.55}}
\newlabel{svae}{{53}{65}{Sampling process of VAEs.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Reparameterization trick for VAEs.\relax }}{67}{figure.caption.56}}
\newlabel{Reparam}{{54}{67}{Reparameterization trick for VAEs.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Framework of VAEs.\relax }}{67}{figure.caption.57}}
\newlabel{VAE_Process}{{55}{67}{Framework of VAEs.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces Generated faces\relax }}{68}{figure.caption.59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Generative adversarial networks (GAN)}{68}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces GAN\relax }}{69}{figure.caption.60}}
\newlabel{gan}{{57}{69}{GAN\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces GAN Example\relax }}{69}{figure.caption.61}}
\newlabel{gan1}{{58}{69}{GAN Example\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces GAN Example\relax }}{70}{figure.caption.62}}
\newlabel{gan2}{{59}{70}{GAN Example\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces Mode collapse. Top: "Unrolled GAN", bottom: standard GAN\relax }}{72}{figure.caption.63}}
\newlabel{mc}{{60}{72}{Mode collapse. Top: "Unrolled GAN", bottom: standard GAN\relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Wasserstein GAN}{72}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}WGAN}{74}{subsubsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces WGAN algorithm\relax }}{75}{figure.caption.64}}
\newlabel{wgan}{{61}{75}{WGAN algorithm\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces GAN algorithm\relax }}{75}{figure.caption.65}}
\newlabel{gan_alg}{{62}{75}{GAN algorithm\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces Wasserstein distance is highly correlated with the generator's convergence and sample quality.\relax }}{76}{figure.caption.66}}
\newlabel{wass_qual}{{63}{76}{Wasserstein distance is highly correlated with the generator's convergence and sample quality.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Gradient penalty}{76}{subsubsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {64}{\ignorespaces (left) gradient norms of deep WGAN critics during training on the Swiss Roll dateset either expolde or vanish when using weight clipping, but not when using a gradient penalty. (right) Weight clipping pushes weights towards the extremes of the clipping range, unlike gradient penalty.\relax }}{76}{figure.caption.67}}
\newlabel{explode}{{64}{76}{(left) gradient norms of deep WGAN critics during training on the Swiss Roll dateset either expolde or vanish when using weight clipping, but not when using a gradient penalty. (right) Weight clipping pushes weights towards the extremes of the clipping range, unlike gradient penalty.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {65}{\ignorespaces Weight clipping reduces the capacity of the critic f and limits the capability to model complex functions.\relax }}{77}{figure.caption.68}}
\newlabel{value}{{65}{77}{Weight clipping reduces the capacity of the critic f and limits the capability to model complex functions.\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {66}{\ignorespaces WGAN Gradient Penalty.\relax }}{78}{figure.caption.69}}
\newlabel{wgan_gp}{{66}{78}{WGAN Gradient Penalty.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Other GANs}{78}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {67}{\ignorespaces WGAN Gradient Penalty. Experimental results\relax }}{79}{figure.caption.70}}
\newlabel{wgan_gp_exp}{{67}{79}{WGAN Gradient Penalty. Experimental results\relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {68}{\ignorespaces cGAN\relax }}{79}{figure.caption.71}}
\newlabel{cGAN}{{68}{79}{cGAN\relax }{figure.caption.71}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Other questions in unsupervised learning}{80}{subsection.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Sequential decision-making: from bandits to deep reinforcement learning}{81}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Intro}{81}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {69}{\ignorespaces Bandit example\relax }}{81}{figure.caption.72}}
\newlabel{band_ex}{{69}{81}{Bandit example\relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {70}{\ignorespaces Online advertising\relax }}{82}{figure.caption.73}}
\newlabel{online_ad}{{70}{82}{Online advertising\relax }{figure.caption.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Bandits}{82}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {71}{\ignorespaces Adaptive clinical trials\relax }}{83}{figure.caption.74}}
\newlabel{ada_ct}{{71}{83}{Adaptive clinical trials\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {72}{\ignorespaces Robotics\relax }}{84}{figure.caption.75}}
\newlabel{robo}{{72}{84}{Robotics\relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {73}{\ignorespaces Reward distribution for two arms\relax }}{84}{figure.caption.76}}
\newlabel{rewards}{{73}{84}{Reward distribution for two arms\relax }{figure.caption.76}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Policies and regret analysis}{85}{subsubsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {74}{\ignorespaces Optimism Principle\relax }}{86}{figure.caption.77}}
\newlabel{opti}{{74}{86}{Optimism Principle\relax }{figure.caption.77}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Comparing policies}{87}{subsubsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {75}{\ignorespaces K=5, $\sigma =0.01$\relax }}{88}{figure.caption.78}}
\newlabel{K=5.sigma=0.01}{{75}{88}{K=5, $\sigma =0.01$\relax }{figure.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {76}{\ignorespaces K=5, $\sigma =0.1$\relax }}{89}{figure.caption.79}}
\newlabel{K=5.sigma=0.1}{{76}{89}{K=5, $\sigma =0.1$\relax }{figure.caption.79}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Adversarial bandits}{89}{subsubsection.5.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {77}{\ignorespaces K=2, $\sigma =0.01$\relax }}{90}{figure.caption.80}}
\newlabel{K=2.sigma=0.01}{{77}{90}{K=2, $\sigma =0.01$\relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {78}{\ignorespaces Thompson sampling\relax }}{91}{figure.caption.81}}
\newlabel{Thompson sampling}{{78}{91}{Thompson sampling\relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Contextual Bandits}{93}{subsubsection.5.2.4}}
\newlabel{Stochastic Contextual Bandits: Parametric Approach III}{{\caption@xref {Stochastic Contextual Bandits: Parametric Approach III}{ on input line 4439}}{95}{Contextual Bandits}{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {79}{\ignorespaces Stochastic Contextual Bandits: Parametric Approach III\relax }}{95}{figure.caption.82}}
\newlabel{Yang and Zhu (2002)}{{\caption@xref {Yang and Zhu (2002)}{ on input line 4452}}{95}{Contextual Bandits}{figure.caption.83}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {80}{\ignorespaces SYang and Zhu (2002)\relax }}{95}{figure.caption.83}}
\newlabel{Adversarial Contexts with Stochastic Rewards 1}{{\caption@xref {Adversarial Contexts with Stochastic Rewards 1}{ on input line 4474}}{96}{Contextual Bandits}{figure.caption.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {81}{\ignorespaces Adversarial Contexts with Stochastic Rewards 2\relax }}{96}{figure.caption.84}}
\newlabel{Adversarial Contexts with Stochastic Rewards 2}{{\caption@xref {Adversarial Contexts with Stochastic Rewards 2}{ on input line 4491}}{96}{Contextual Bandits}{figure.caption.85}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {82}{\ignorespaces Adversarial Contexts with Stochastic Rewards 2\relax }}{96}{figure.caption.85}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Software and Miscellanea}{97}{subsubsection.5.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Reinforcement learning}{97}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Setup}{97}{subsubsection.5.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}L1. Introduction}{97}{subsubsection.5.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {83}{\ignorespaces Example RL\relax }}{98}{figure.caption.86}}
\newlabel{Example RL}{{83}{98}{Example RL\relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {84}{\ignorespaces Agent and Environment\relax }}{99}{figure.caption.87}}
\newlabel{Agent and Environment}{{84}{99}{Agent and Environment\relax }{figure.caption.87}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Definitions}{99}{subsubsection.5.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Relation to Contextual Bandits}{101}{subsubsection.5.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {85}{\ignorespaces Comparing bandits and RL\relax }}{102}{figure.caption.88}}
\newlabel{Comparing bandits and RL}{{85}{102}{Comparing bandits and RL\relax }{figure.caption.88}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5}Markov Decision Process}{102}{subsubsection.5.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {86}{\ignorespaces Maze and Value-based\relax }}{104}{figure.caption.89}}
\newlabel{maze}{{86}{104}{Maze and Value-based\relax }{figure.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {87}{\ignorespaces Policy and Model-based\relax }}{105}{figure.caption.90}}
\newlabel{maze2}{{87}{105}{Policy and Model-based\relax }{figure.caption.90}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6}Planning by dynamic programming}{106}{subsubsection.5.3.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7}Model-free prediction}{106}{subsubsection.5.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {88}{\ignorespaces Unified view of RL\relax }}{107}{figure.caption.91}}
\newlabel{Unified view of RL}{{88}{107}{Unified view of RL\relax }{figure.caption.91}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.8}Model-free control}{107}{subsubsection.5.3.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.9}Scaling up RL. Value function approximation}{108}{subsubsection.5.3.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.10}Policy gradient}{109}{subsubsection.5.3.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.11}Integrating learning and planning}{110}{subsubsection.5.3.11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.12}Hierarchical RL}{111}{subsubsection.5.3.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {89}{\ignorespaces Maze Task.\relax }}{112}{figure.caption.92}}
\newlabel{maze10}{{89}{112}{Maze Task.\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.13}Task-agnostic RL}{116}{subsubsection.5.3.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Other topics}{117}{subsection.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Special topics}{118}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Adversarial examples}{118}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {90}{\ignorespaces A conceptual illustration of “natural” vs. “adversarial” decision boundaries.\relax }}{122}{figure.caption.93}}
\newlabel{natl_adv}{{90}{122}{A conceptual illustration of “natural” vs. “adversarial” decision boundaries.\relax }{figure.caption.93}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {91}{\ignorespaces EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY.\relax }}{123}{figure.caption.94}}
\newlabel{inv}{{91}{123}{EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY.\relax }{figure.caption.94}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Neural ODEs}{124}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Physics informed NNs (PINNs)}{124}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Information bottleneck and invariance}{125}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Gradient-based optimization}{127}{subsection.6.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {92}{\ignorespaces Gradient descent\relax }}{128}{figure.caption.95}}
\newlabel{Gradient descent}{{92}{128}{Gradient descent\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {93}{\ignorespaces Batch gradient descent vs. SGD fluctuation (Source: Wikipedia)\relax }}{129}{figure.caption.96}}
\newlabel{Batch gradient descent vs. SGD fluctuation}{{93}{129}{Batch gradient descent vs. SGD fluctuation (Source: Wikipedia)\relax }{figure.caption.96}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {94}{\ignorespaces Tradeoffs\relax }}{130}{figure.caption.97}}
\newlabel{Tradeoffs}{{94}{130}{Tradeoffs\relax }{figure.caption.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {95}{\ignorespaces Ravine\relax }}{130}{figure.caption.98}}
\newlabel{Ravine}{{95}{130}{Ravine\relax }{figure.caption.98}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {96}{\ignorespaces Ravine in optimization\relax }}{130}{figure.caption.98}}
\@writefile{lof}{\contentsline {figure}{\numberline {97}{\ignorespaces SGD without momentum\relax }}{131}{figure.caption.99}}
\newlabel{SGD with momentum}{{97}{131}{SGD without momentum\relax }{figure.caption.99}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {98}{\ignorespaces SGD with momentum\relax }}{131}{figure.caption.99}}
\@writefile{lof}{\contentsline {figure}{\numberline {99}{\ignorespaces Optimization with momentum (Source: \href  {https://distill.pub/2017/momentum/}{distill.pub})\relax }}{131}{figure.caption.100}}
\newlabel{Momentum}{{99}{131}{Optimization with momentum (Source: \href {https://distill.pub/2017/momentum/}{distill.pub})\relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {100}{\ignorespaces Nesterov\relax }}{132}{figure.caption.101}}
\newlabel{Nesterov}{{100}{132}{Nesterov\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {101}{\ignorespaces Animations\relax }}{133}{figure.caption.102}}
\newlabel{animations}{{101}{133}{Animations\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {102}{\ignorespaces Logistic regression experiment\relax }}{135}{figure.caption.103}}
\newlabel{experiment_logistic_regression}{{102}{135}{Logistic regression experiment\relax }{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {103}{\ignorespaces Experiment: Convolutional Neural Networks\relax }}{135}{figure.caption.104}}
\newlabel{experiment_cnn}{{103}{135}{Experiment: Convolutional Neural Networks\relax }{figure.caption.104}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {104}{\ignorespaces NMT1\relax }}{137}{figure.caption.105}}
\newlabel{NMT1}{{104}{137}{NMT1\relax }{figure.caption.105}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Design of new architectures - gradient computations}{137}{subsection.6.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {105}{\ignorespaces NMT2\relax }}{138}{figure.caption.106}}
\newlabel{NMT2}{{105}{138}{NMT2\relax }{figure.caption.106}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Distributed training}{139}{subsection.6.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {106}{\ignorespaces MapReduce\relax }}{140}{figure.caption.107}}
\newlabel{mr}{{106}{140}{MapReduce\relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {107}{\ignorespaces Distributed GD\relax }}{140}{figure.caption.108}}
\newlabel{dgd}{{107}{140}{Distributed GD\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.1}Notes from Smola's class}{140}{subsubsection.6.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {108}{\ignorespaces FireCaffe: near-linear acceleration of deep neural network training on compute clusters, Iandola et al 2016\relax }}{141}{figure.caption.109}}
\newlabel{FireCaffe}{{108}{141}{FireCaffe: near-linear acceleration of deep neural network training on compute clusters, Iandola et al 2016\relax }{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {109}{\ignorespaces Universal relationship between batch size and training speed\relax }}{144}{figure.caption.110}}
\newlabel{Bsts}{{109}{144}{Universal relationship between batch size and training speed\relax }{figure.caption.110}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}AutoML}{144}{subsection.6.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {110}{\ignorespaces Neural Architecture Search\relax }}{145}{figure.caption.111}}
\newlabel{nas}{{110}{145}{Neural Architecture Search\relax }{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {111}{\ignorespaces Basic Neural Architecture Search Spaces\relax }}{145}{figure.caption.112}}
\newlabel{nas2}{{111}{145}{Basic Neural Architecture Search Spaces\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {112}{\ignorespaces Cell Search Spaces.\relax }}{146}{figure.caption.113}}
\newlabel{nas3}{{112}{146}{Cell Search Spaces.\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {113}{\ignorespaces NAS as Hyperparameter Optimization\relax }}{146}{figure.caption.114}}
\newlabel{nas4}{{113}{146}{NAS as Hyperparameter Optimization\relax }{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {114}{\ignorespaces NAS with RL.\relax }}{147}{figure.caption.115}}
\newlabel{nas6}{{114}{147}{NAS with RL.\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {115}{\ignorespaces Controller.\relax }}{147}{figure.caption.116}}
\newlabel{nas7}{{115}{147}{Controller.\relax }{figure.caption.116}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {116}{\ignorespaces Evolution.\relax }}{148}{figure.caption.117}}
\newlabel{nas8}{{116}{148}{Evolution.\relax }{figure.caption.117}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {117}{\ignorespaces Comparison: Evolution, RL.\relax }}{149}{figure.caption.118}}
\newlabel{nas9}{{117}{149}{Comparison: Evolution, RL.\relax }{figure.caption.118}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {118}{\ignorespaces One-shot NAS.\relax }}{149}{figure.caption.119}}
\newlabel{nas10}{{118}{149}{One-shot NAS.\relax }{figure.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {119}{\ignorespaces DARTS\relax }}{150}{figure.caption.120}}
\newlabel{darts}{{119}{150}{DARTS\relax }{figure.caption.120}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {120}{\ignorespaces Google's AutoML system pipeline\relax }}{152}{figure.caption.121}}
\newlabel{automl}{{120}{152}{Google's AutoML system pipeline\relax }{figure.caption.121}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9}Biological plausibility}{153}{subsection.6.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.10}Accessibility + Human-centric AI}{153}{subsection.6.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {121}{\ignorespaces Penn AI\relax }}{154}{figure.caption.122}}
\newlabel{Penn AI}{{121}{154}{Penn AI\relax }{figure.caption.122}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11}Explainability (and interpretability)}{154}{subsection.6.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {122}{\ignorespaces Saliency maps\relax }}{155}{figure.caption.123}}
\newlabel{saliency}{{122}{155}{Saliency maps\relax }{figure.caption.123}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.12}Model compression}{157}{subsection.6.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {123}{\ignorespaces Lottery ticket hypothesis\relax }}{158}{figure.caption.124}}
\newlabel{lot}{{123}{158}{Lottery ticket hypothesis\relax }{figure.caption.124}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13}Others}{159}{subsection.6.13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.1}List}{159}{subsubsection.6.13.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.2}Privacy}{160}{subsubsection.6.13.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.3}Applications}{161}{subsubsection.6.13.3}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Theory}{161}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Why do we need theory?}{161}{subsection.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {124}{\ignorespaces Model architecture using a graph-based convolutional neural network for molecular embedding.\relax }}{162}{figure.caption.125}}
\newlabel{gcnn_mol}{{124}{162}{Model architecture using a graph-based convolutional neural network for molecular embedding.\relax }{figure.caption.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {125}{\ignorespaces 3-Node Neural Network that is NP-Complete to train. Blum and Rivest\relax }}{163}{figure.caption.126}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Computational complexity and learning}{163}{subsection.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Approximation theory}{165}{subsection.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Optimization}{167}{subsection.7.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Generalization}{168}{subsection.7.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Nonparametric function estimation}{170}{subsection.7.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7}Harmonic analysis}{170}{subsection.7.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8}Probabilistic ML}{170}{subsection.7.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {126}{\ignorespaces Deep Scattering Network, Boelcskei \& Wiatkowski, 2015\relax }}{171}{figure.caption.127}}
\newlabel{dsn}{{126}{171}{Deep Scattering Network, Boelcskei \& Wiatkowski, 2015\relax }{figure.caption.127}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {127}{\ignorespaces Rendering Mixture Model, Baraniuk, Patel, etc\relax }}{171}{figure.caption.128}}
\newlabel{rmm}{{127}{171}{Rendering Mixture Model, Baraniuk, Patel, etc\relax }{figure.caption.128}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9}Information geometry}{171}{subsection.7.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10}Random Matrix Theory}{172}{subsection.7.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11}Physics}{173}{subsection.7.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.12}Geometry}{175}{subsection.7.12}}
\@writefile{toc}{\contentsline {section}{\numberline {8}How to learn practical DL}{175}{section.8}}
=======
\@writefile{toc}{\contentsline {section}{\numberline {2}Convolutional neural networks (CNNs)}{18}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The problem and model}{18}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Creative architectures.\relax }}{19}{figure.caption.13}}
\newlabel{arch}{{11}{19}{Creative architectures.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces LeNet-5. (LeCun, 1998)\relax }}{21}{figure.caption.14}}
\newlabel{lenet5}{{12}{21}{LeNet-5. (LeCun, 1998)\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces AlexNet. Krizhevsky et al (2012, NIPS), Won ILSVRC 2012.\relax }}{21}{figure.caption.15}}
\newlabel{AlexNet}{{13}{21}{AlexNet. Krizhevsky et al (2012, NIPS), Won ILSVRC 2012.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces VGG. (Simonyan, Zisserman, 2015).\relax }}{21}{figure.caption.16}}
\newlabel{VGG}{{14}{21}{VGG. (Simonyan, Zisserman, 2015).\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Images that maximize activation. The neurons selected for these images are the output neurons that a DNN uses to classify images as bananas etc.\relax }}{22}{figure.caption.17}}
\newlabel{vis}{{15}{22}{Images that maximize activation. The neurons selected for these images are the output neurons that a DNN uses to classify images as bananas etc.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Other methodology}{22}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces R-CNN.\relax }}{23}{figure.caption.18}}
\newlabel{rcnn}{{16}{23}{R-CNN.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training}{23}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Graph CNN}{23}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Graph CNN.\relax }}{26}{figure.caption.19}}
\newlabel{gcnn}{{17}{26}{Graph CNN.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Graph Coarsening and Pooling.\relax }}{27}{figure.caption.20}}
\newlabel{gcp}{{18}{27}{Graph Coarsening and Pooling.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Other aspects}{29}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Shapes beyond images, invariance}{30}{subsection.2.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Spatial Transformer Networks.\relax }}{32}{figure.caption.21}}
\newlabel{STN}{{19}{32}{Spatial Transformer Networks.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Spatial Transformer Networks}{32}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Image denoising/compression}{33}{subsection.2.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Unsupervised Adversarial Image Reconstruction.\relax }}{34}{figure.caption.22}}
\newlabel{UAIR}{{20}{34}{Unsupervised Adversarial Image Reconstruction.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Unsupervised Adversarial Image Reconstruction results example.\relax }}{34}{figure.caption.23}}
\newlabel{UAIRr}{{21}{34}{Unsupervised Adversarial Image Reconstruction results example.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Deep decoder.\relax }}{35}{figure.caption.24}}
\newlabel{DD}{{22}{35}{Deep decoder.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Recurrent neural networks (RNNs)}{35}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Setup}{35}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces RNNs.\relax }}{37}{figure.caption.25}}
\newlabel{rnn}{{23}{37}{RNNs.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces LSTM. Courtesy of Andrew Ng's course.\relax }}{38}{figure.caption.26}}
\newlabel{lstm}{{24}{38}{LSTM. Courtesy of Andrew Ng's course.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Attention Model.\relax }}{38}{figure.caption.27}}
\newlabel{attn}{{25}{38}{Attention Model.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Captioning, Google Brain, 2016. Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. \url  {https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html}\relax }}{39}{figure.caption.28}}
\newlabel{c}{{26}{39}{Captioning, Google Brain, 2016. Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. \url {https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html}\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Wavenet.\relax }}{40}{figure.caption.29}}
\newlabel{wavenet}{{27}{40}{Wavenet.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sequence Learning}{40}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Motivation}{40}{subsubsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces MLP.\relax }}{41}{figure.caption.30}}
\newlabel{MLP}{{28}{41}{MLP.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces RNN types.\relax }}{41}{figure.caption.31}}
\newlabel{rnn-types}{{29}{41}{RNN types.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sequence Models}{41}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}RNNs}{41}{subsubsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Simple RNN.\relax }}{42}{figure.caption.32}}
\newlabel{Simple RNN}{{30}{42}{Simple RNN.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Teacher forcing.\relax }}{42}{figure.caption.33}}
\newlabel{Teacher forcing}{{31}{42}{Teacher forcing.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Training Challenges}{43}{subsubsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Gradient Clipping.\relax }}{45}{figure.caption.34}}
\newlabel{Gradient Clipping}{{32}{45}{Gradient Clipping.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces ReLU.\relax }}{45}{figure.caption.35}}
\newlabel{ReLU}{{33}{45}{ReLU.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}LSTM and GRU}{45}{subsubsection.3.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces LSTM.\relax }}{46}{figure.caption.36}}
\newlabel{LSTM}{{34}{46}{LSTM.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Neural Machine Translation in 2016.\relax }}{47}{figure.caption.37}}
\newlabel{Neural Machine Translation in 2016}{{35}{47}{Neural Machine Translation in 2016.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Machine Translation}{47}{subsection.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Translation quality vs. sentence length. RNN left, SMT right.\relax }}{49}{figure.caption.38}}
\newlabel{Encoder-Decoder Model}{{36}{49}{Translation quality vs. sentence length. RNN left, SMT right.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Sample output of two RNN models compared to the SMT system, Moses.\relax }}{49}{figure.caption.39}}
\newlabel{Sample-rnn}{{37}{49}{Sample output of two RNN models compared to the SMT system, Moses.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Attention}{49}{subsubsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Attention\relax }}{50}{figure.caption.40}}
\newlabel{Attention}{{38}{50}{Attention\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Transformer Model}{50}{subsubsection.3.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Encoder-Decoder Model with Attention.\relax }}{51}{figure.caption.41}}
\newlabel{Encoder-Decoder Model with Attention}{{39}{51}{Encoder-Decoder Model with Attention.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces A sample alignment found by RNNsearch-50.\relax }}{51}{figure.caption.42}}
\newlabel{A sample alignment found by RNNsearch-50}{{40}{51}{A sample alignment found by RNNsearch-50.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces $n$ is sequence length, $d$ is representation dimension, $k$ is kernel size of convolutions, $r$ is the size of the neighborhood in restricted self-attention.\relax }}{52}{figure.caption.43}}
\newlabel{NMT Model Comparison}{{41}{52}{$n$ is sequence length, $d$ is representation dimension, $k$ is kernel size of convolutions, $r$ is the size of the neighborhood in restricted self-attention.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Transformer Model.\relax }}{52}{figure.caption.44}}
\newlabel{Transformer Model}{{42}{52}{Transformer Model.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Self-Attention.\relax }}{53}{figure.caption.45}}
\newlabel{Self-Attention}{{43}{53}{Self-Attention.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Self-Attention 1.\relax }}{54}{figure.caption.46}}
\newlabel{Self-Attention 1}{{44}{54}{Self-Attention 1.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Self-Attention 2\relax }}{54}{figure.caption.47}}
\newlabel{Self-Attention 2}{{45}{54}{Self-Attention 2\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Self-Attention 3\relax }}{55}{figure.caption.48}}
\newlabel{Self-Attention 3}{{46}{55}{Self-Attention 3\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces The Transformer outperforms other state-of-the-art models at a fraction of the training cost. FLOPS is floating point operations.\relax }}{55}{figure.caption.49}}
\newlabel{TheT}{{47}{55}{The Transformer outperforms other state-of-the-art models at a fraction of the training cost. FLOPS is floating point operations.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Image + Text}{56}{subsection.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Deep Visual-Semantic Alignments for Generating Image Descriptions\relax }}{57}{figure.caption.50}}
\newlabel{Caption}{{48}{57}{Deep Visual-Semantic Alignments for Generating Image Descriptions\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Others}{57}{subsection.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Unsupervised learning}{57}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Setup}{57}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces TCN\relax }}{58}{figure.caption.51}}
\newlabel{TCN}{{49}{58}{TCN\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}PCA, AE, VAE}{58}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces AE\relax }}{60}{figure.caption.52}}
\newlabel{ae0}{{50}{60}{AE\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces VAE\relax }}{60}{figure.caption.53}}
\newlabel{vae}{{51}{60}{VAE\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces Sampling process of VAEs.\relax }}{61}{figure.caption.54}}
\newlabel{svae}{{52}{61}{Sampling process of VAEs.\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Reparameterization trick for VAEs.\relax }}{62}{figure.caption.55}}
\newlabel{Reparam}{{53}{62}{Reparameterization trick for VAEs.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Framework of VAEs.\relax }}{62}{figure.caption.56}}
\newlabel{VAE_Process}{{54}{62}{Framework of VAEs.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Generated faces\relax }}{63}{figure.caption.58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Generative adversarial networks (GAN)}{63}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces GAN\relax }}{64}{figure.caption.59}}
\newlabel{gan}{{56}{64}{GAN\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces GAN Example\relax }}{64}{figure.caption.60}}
\newlabel{gan1}{{57}{64}{GAN Example\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces GAN Example\relax }}{65}{figure.caption.61}}
\newlabel{gan2}{{58}{65}{GAN Example\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces Mode collapse. Top: "Unrolled GAN", bottom: standard GAN\relax }}{67}{figure.caption.62}}
\newlabel{mc}{{59}{67}{Mode collapse. Top: "Unrolled GAN", bottom: standard GAN\relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Wasserstein GAN}{67}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}WGAN}{69}{subsubsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces WGAN algorithm\relax }}{70}{figure.caption.63}}
\newlabel{wgan}{{60}{70}{WGAN algorithm\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces GAN algorithm\relax }}{70}{figure.caption.64}}
\newlabel{gan_alg}{{61}{70}{GAN algorithm\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces Wasserstein distance is highly correlated with the generator's convergence and sample quality.\relax }}{71}{figure.caption.65}}
\newlabel{wass_qual}{{62}{71}{Wasserstein distance is highly correlated with the generator's convergence and sample quality.\relax }{figure.caption.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Gradient penalty}{71}{subsubsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces (left) gradient norms of deep WGAN critics during training on the Swiss Roll dateset either expolde or vanish when using weight clipping, but not when using a gradient penalty. (right) Weight clipping pushes weights towards the extremes of the clipping range, unlike gradient penalty.\relax }}{71}{figure.caption.66}}
\newlabel{explode}{{63}{71}{(left) gradient norms of deep WGAN critics during training on the Swiss Roll dateset either expolde or vanish when using weight clipping, but not when using a gradient penalty. (right) Weight clipping pushes weights towards the extremes of the clipping range, unlike gradient penalty.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {64}{\ignorespaces Weight clipping reduces the capacity of the critic f and limits the capability to model complex functions.\relax }}{72}{figure.caption.67}}
\newlabel{value}{{64}{72}{Weight clipping reduces the capacity of the critic f and limits the capability to model complex functions.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {65}{\ignorespaces WGAN Gradient Penalty.\relax }}{73}{figure.caption.68}}
\newlabel{wgan_gp}{{65}{73}{WGAN Gradient Penalty.\relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Other GANs}{73}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {66}{\ignorespaces WGAN Gradient Penalty. Experimental results\relax }}{74}{figure.caption.69}}
\newlabel{wgan_gp_exp}{{66}{74}{WGAN Gradient Penalty. Experimental results\relax }{figure.caption.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {67}{\ignorespaces cGAN\relax }}{74}{figure.caption.70}}
\newlabel{cGAN}{{67}{74}{cGAN\relax }{figure.caption.70}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Other questions in unsupervised learning}{75}{subsection.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Sequential decision-making: from bandits to deep reinforcement learning}{76}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Intro}{76}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {68}{\ignorespaces Bandit example\relax }}{76}{figure.caption.71}}
\newlabel{band_ex}{{68}{76}{Bandit example\relax }{figure.caption.71}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {69}{\ignorespaces Online advertising\relax }}{77}{figure.caption.72}}
\newlabel{online_ad}{{69}{77}{Online advertising\relax }{figure.caption.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Bandits}{77}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {70}{\ignorespaces Adaptive clinical trials\relax }}{78}{figure.caption.73}}
\newlabel{ada_ct}{{70}{78}{Adaptive clinical trials\relax }{figure.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {71}{\ignorespaces Robotics\relax }}{79}{figure.caption.74}}
\newlabel{robo}{{71}{79}{Robotics\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {72}{\ignorespaces Reward distribution for two arms\relax }}{79}{figure.caption.75}}
\newlabel{rewards}{{72}{79}{Reward distribution for two arms\relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Policies and regret analysis}{80}{subsubsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {73}{\ignorespaces Optimism Principle\relax }}{81}{figure.caption.76}}
\newlabel{opti}{{73}{81}{Optimism Principle\relax }{figure.caption.76}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Comparing policies}{82}{subsubsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {74}{\ignorespaces K=5, $\sigma =0.01$\relax }}{83}{figure.caption.77}}
\newlabel{K=5.sigma=0.01}{{74}{83}{K=5, $\sigma =0.01$\relax }{figure.caption.77}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {75}{\ignorespaces K=5, $\sigma =0.1$\relax }}{84}{figure.caption.78}}
\newlabel{K=5.sigma=0.1}{{75}{84}{K=5, $\sigma =0.1$\relax }{figure.caption.78}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Adversarial bandits}{84}{subsubsection.5.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {76}{\ignorespaces K=2, $\sigma =0.01$\relax }}{85}{figure.caption.79}}
\newlabel{K=2.sigma=0.01}{{76}{85}{K=2, $\sigma =0.01$\relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {77}{\ignorespaces Thompson sampling\relax }}{86}{figure.caption.80}}
\newlabel{Thompson sampling}{{77}{86}{Thompson sampling\relax }{figure.caption.80}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Contextual Bandits}{88}{subsubsection.5.2.4}}
\newlabel{Stochastic Contextual Bandits: Parametric Approach III}{{\caption@xref {Stochastic Contextual Bandits: Parametric Approach III}{ on input line 4191}}{90}{Contextual Bandits}{figure.caption.81}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {78}{\ignorespaces Stochastic Contextual Bandits: Parametric Approach III\relax }}{90}{figure.caption.81}}
\newlabel{Yang and Zhu (2002)}{{\caption@xref {Yang and Zhu (2002)}{ on input line 4204}}{90}{Contextual Bandits}{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {79}{\ignorespaces SYang and Zhu (2002)\relax }}{90}{figure.caption.82}}
\newlabel{Adversarial Contexts with Stochastic Rewards 1}{{\caption@xref {Adversarial Contexts with Stochastic Rewards 1}{ on input line 4226}}{91}{Contextual Bandits}{figure.caption.83}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {80}{\ignorespaces Adversarial Contexts with Stochastic Rewards 2\relax }}{91}{figure.caption.83}}
\newlabel{Adversarial Contexts with Stochastic Rewards 2}{{\caption@xref {Adversarial Contexts with Stochastic Rewards 2}{ on input line 4243}}{91}{Contextual Bandits}{figure.caption.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {81}{\ignorespaces Adversarial Contexts with Stochastic Rewards 2\relax }}{91}{figure.caption.84}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Software and Miscellanea}{92}{subsubsection.5.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Reinforcement learning}{92}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Setup}{92}{subsubsection.5.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}L1. Introduction}{92}{subsubsection.5.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {82}{\ignorespaces Example RL\relax }}{93}{figure.caption.85}}
\newlabel{Example RL}{{82}{93}{Example RL\relax }{figure.caption.85}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {83}{\ignorespaces Agent and Environment\relax }}{94}{figure.caption.86}}
\newlabel{Agent and Environment}{{83}{94}{Agent and Environment\relax }{figure.caption.86}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Definitions}{94}{subsubsection.5.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Relation to Contextual Bandits}{96}{subsubsection.5.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {84}{\ignorespaces Comparing bandits and RL\relax }}{97}{figure.caption.87}}
\newlabel{Comparing bandits and RL}{{84}{97}{Comparing bandits and RL\relax }{figure.caption.87}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5}Markov Decision Process}{97}{subsubsection.5.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {85}{\ignorespaces Maze and Value-based\relax }}{99}{figure.caption.88}}
\newlabel{maze}{{85}{99}{Maze and Value-based\relax }{figure.caption.88}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {86}{\ignorespaces Policy and Model-based\relax }}{100}{figure.caption.89}}
\newlabel{maze2}{{86}{100}{Policy and Model-based\relax }{figure.caption.89}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6}Planning by dynamic programming}{101}{subsubsection.5.3.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7}Model-free prediction}{101}{subsubsection.5.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {87}{\ignorespaces Unified view of RL\relax }}{102}{figure.caption.90}}
\newlabel{Unified view of RL}{{87}{102}{Unified view of RL\relax }{figure.caption.90}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.8}Model-free control}{102}{subsubsection.5.3.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.9}Scaling up RL. Value function approximation}{103}{subsubsection.5.3.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.10}Policy gradient}{104}{subsubsection.5.3.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.11}Integrating learning and planning}{105}{subsubsection.5.3.11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.12}Hierarchical RL}{106}{subsubsection.5.3.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {88}{\ignorespaces Maze Task.\relax }}{107}{figure.caption.91}}
\newlabel{maze10}{{88}{107}{Maze Task.\relax }{figure.caption.91}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.13}Task-agnostic RL}{111}{subsubsection.5.3.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Other topics}{112}{subsection.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Special topics}{113}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Adversarial examples}{113}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {89}{\ignorespaces A conceptual illustration of “natural” vs. “adversarial” decision boundaries.\relax }}{117}{figure.caption.92}}
\newlabel{natl_adv}{{89}{117}{A conceptual illustration of “natural” vs. “adversarial” decision boundaries.\relax }{figure.caption.92}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {90}{\ignorespaces EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY.\relax }}{118}{figure.caption.93}}
\newlabel{inv}{{90}{118}{EXCESSIVE INVARIANCE CAUSES ADVERSARIAL VULNERABILITY.\relax }{figure.caption.93}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Neural ODEs}{118}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Physics informed NNs (PINNs)}{119}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Information bottleneck and invariance}{120}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Gradient-based optimization}{122}{subsection.6.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {91}{\ignorespaces Gradient descent\relax }}{123}{figure.caption.94}}
\newlabel{Gradient descent}{{91}{123}{Gradient descent\relax }{figure.caption.94}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {92}{\ignorespaces Batch gradient descent vs. SGD fluctuation (Source: Wikipedia)\relax }}{124}{figure.caption.95}}
\newlabel{Batch gradient descent vs. SGD fluctuation}{{92}{124}{Batch gradient descent vs. SGD fluctuation (Source: Wikipedia)\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {93}{\ignorespaces Tradeoffs\relax }}{124}{figure.caption.96}}
\newlabel{Tradeoffs}{{93}{124}{Tradeoffs\relax }{figure.caption.96}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {94}{\ignorespaces Ravine\relax }}{125}{figure.caption.97}}
\newlabel{Ravine}{{94}{125}{Ravine\relax }{figure.caption.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {95}{\ignorespaces Ravine in optimization\relax }}{125}{figure.caption.97}}
\@writefile{lof}{\contentsline {figure}{\numberline {96}{\ignorespaces SGD without momentum\relax }}{126}{figure.caption.98}}
\newlabel{SGD with momentum}{{96}{126}{SGD without momentum\relax }{figure.caption.98}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {97}{\ignorespaces SGD with momentum\relax }}{126}{figure.caption.98}}
\@writefile{lof}{\contentsline {figure}{\numberline {98}{\ignorespaces Optimization with momentum (Source: \href  {https://distill.pub/2017/momentum/}{distill.pub})\relax }}{126}{figure.caption.99}}
\newlabel{Momentum}{{98}{126}{Optimization with momentum (Source: \href {https://distill.pub/2017/momentum/}{distill.pub})\relax }{figure.caption.99}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {99}{\ignorespaces Nesterov\relax }}{126}{figure.caption.100}}
\newlabel{Nesterov}{{99}{126}{Nesterov\relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {100}{\ignorespaces Animations\relax }}{128}{figure.caption.101}}
\newlabel{animations}{{100}{128}{Animations\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {101}{\ignorespaces Logistic regression experiment\relax }}{130}{figure.caption.102}}
\newlabel{experiment_logistic_regression}{{101}{130}{Logistic regression experiment\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {102}{\ignorespaces Experiment: Convolutional Neural Networks\relax }}{130}{figure.caption.103}}
\newlabel{experiment_cnn}{{102}{130}{Experiment: Convolutional Neural Networks\relax }{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {103}{\ignorespaces NMT1\relax }}{132}{figure.caption.104}}
\newlabel{NMT1}{{103}{132}{NMT1\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Design of new architectures - gradient computations}{132}{subsection.6.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {104}{\ignorespaces NMT2\relax }}{133}{figure.caption.105}}
\newlabel{NMT2}{{104}{133}{NMT2\relax }{figure.caption.105}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Distributed training}{134}{subsection.6.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.1}Notes from Smola's class}{134}{subsubsection.6.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {105}{\ignorespaces MapReduce\relax }}{135}{figure.caption.106}}
\newlabel{mr}{{105}{135}{MapReduce\relax }{figure.caption.106}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {106}{\ignorespaces Distributed GD\relax }}{135}{figure.caption.107}}
\newlabel{dgd}{{106}{135}{Distributed GD\relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {107}{\ignorespaces FireCaffe: near-linear acceleration of deep neural network training on compute clusters, Iandola et al 2016\relax }}{136}{figure.caption.108}}
\newlabel{FireCaffe}{{107}{136}{FireCaffe: near-linear acceleration of deep neural network training on compute clusters, Iandola et al 2016\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}AutoML}{138}{subsection.6.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {108}{\ignorespaces Neural Architecture Search\relax }}{139}{figure.caption.109}}
\newlabel{nas}{{108}{139}{Neural Architecture Search\relax }{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {109}{\ignorespaces Basic Neural Architecture Search Spaces\relax }}{139}{figure.caption.110}}
\newlabel{nas2}{{109}{139}{Basic Neural Architecture Search Spaces\relax }{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {110}{\ignorespaces Cell Search Spaces.\relax }}{140}{figure.caption.111}}
\newlabel{nas3}{{110}{140}{Cell Search Spaces.\relax }{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {111}{\ignorespaces NAS as Hyperparameter Optimization\relax }}{140}{figure.caption.112}}
\newlabel{nas4}{{111}{140}{NAS as Hyperparameter Optimization\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {112}{\ignorespaces NAS with RL.\relax }}{141}{figure.caption.113}}
\newlabel{nas6}{{112}{141}{NAS with RL.\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {113}{\ignorespaces Controller.\relax }}{142}{figure.caption.114}}
\newlabel{nas7}{{113}{142}{Controller.\relax }{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {114}{\ignorespaces Evolution.\relax }}{142}{figure.caption.115}}
\newlabel{nas8}{{114}{142}{Evolution.\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {115}{\ignorespaces Comparison: Evolution, RL.\relax }}{143}{figure.caption.116}}
\newlabel{nas9}{{115}{143}{Comparison: Evolution, RL.\relax }{figure.caption.116}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {116}{\ignorespaces One-shot NAS.\relax }}{143}{figure.caption.117}}
\newlabel{nas10}{{116}{143}{One-shot NAS.\relax }{figure.caption.117}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {117}{\ignorespaces DARTS\relax }}{144}{figure.caption.118}}
\newlabel{darts}{{117}{144}{DARTS\relax }{figure.caption.118}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9}Biological plausibility}{146}{subsection.6.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.10}Accessibility}{147}{subsection.6.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {118}{\ignorespaces Penn AI\relax }}{147}{figure.caption.119}}
\newlabel{Penn AI}{{118}{147}{Penn AI\relax }{figure.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {119}{\ignorespaces Saliency maps\relax }}{148}{figure.caption.120}}
\newlabel{saliency}{{119}{148}{Saliency maps\relax }{figure.caption.120}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11}Explainability (and interpretability)}{148}{subsection.6.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.12}Model compression}{151}{subsection.6.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {120}{\ignorespaces Lottery ticket hypothesis\relax }}{152}{figure.caption.121}}
\newlabel{lot}{{120}{152}{Lottery ticket hypothesis\relax }{figure.caption.121}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13}Others}{153}{subsection.6.13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.1}List}{153}{subsubsection.6.13.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.2}Privacy}{154}{subsubsection.6.13.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.13.3}Applications}{154}{subsubsection.6.13.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {121}{\ignorespaces Model architecture using a graph-based convolutional neural network for molecular embedding.\relax }}{155}{figure.caption.122}}
\newlabel{gcnn_mol}{{121}{155}{Model architecture using a graph-based convolutional neural network for molecular embedding.\relax }{figure.caption.122}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Theory}{155}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Why do we need theory?}{155}{subsection.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {122}{\ignorespaces 3-Node Neural Network that is NP-Complete to train. Blum and Rivest\relax }}{156}{figure.caption.123}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Computational complexity and learning}{156}{subsection.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Approximation theory}{158}{subsection.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Optimization}{160}{subsection.7.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Generalization}{161}{subsection.7.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Nonparametric function estimation}{163}{subsection.7.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7}Harmonic analysis}{163}{subsection.7.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8}Probabilistic ML}{163}{subsection.7.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {123}{\ignorespaces Deep Scattering Network, Boelcskei \& Wiatkowski, 2015\relax }}{164}{figure.caption.124}}
\newlabel{dsn}{{123}{164}{Deep Scattering Network, Boelcskei \& Wiatkowski, 2015\relax }{figure.caption.124}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {124}{\ignorespaces Rendering Mixture Model, Baraniuk, Patel, etc\relax }}{164}{figure.caption.125}}
\newlabel{rmm}{{124}{164}{Rendering Mixture Model, Baraniuk, Patel, etc\relax }{figure.caption.125}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9}Information geometry}{164}{subsection.7.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10}Random Matrix Theory}{165}{subsection.7.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11}Physics}{166}{subsection.7.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.12}Geometry}{168}{subsection.7.12}}
\@writefile{toc}{\contentsline {section}{\numberline {8}How to learn practical DL}{168}{section.8}}
>>>>>>> 36d1093ab5c3bf4ed4298c4a7e51ef121e1f9f5d
